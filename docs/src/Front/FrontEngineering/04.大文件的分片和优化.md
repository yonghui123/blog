<!-- ---
title: 04.大文件的分片和优化
date: 2024-10-26
cover: 
categories:
 - 前端工程化
tags:
 - 前端造轮子
description: 
--- -->


## 如何减少页面阻塞

分片上传的一个首要目标是要尽量避免相同的分片重复上传，服务器必须要能够识别来自各个客户端的各个上传请求中，是否存在于过去分片相同的上传请求，所以服务端需要识别哪些分片是相同的。

我们定义文件内容一样的文件称为相同的文件，但是如果对比文件内容的二进制是一个非常耗时的操作，研究了之后发现可以选择基于文件内容的hash值来判断文件是否相同。

所以整个发送文件的流程就可以大概总结为：
1. 客户端计算分片的hash值，并将该hash值发送给服务端
2. 服务端通知客户端有无对应分片
3. 如果没有该文件分片，将该分片发送给服务端，服务端存储

对整个文件也需要计算整个文件的hash值，判断该文件是否上传过了，如果上传过，则不再上传，直接返回。

根绝上图的流程，可以知道，客户端有两件很重要的事情：
1. 计算分片的hash值
2. 计算整个文件的hash值

计算hash值是一个CPU密集型的任务，所以需要一个处理测罗防止其阻塞主线程。

因此可以对整个大文件上传做一个大胆的假设：绝大部分的文件上传都是新的文件上传

在这个假设的基础上，在处理文件的时候，就不需要等待整个文件的hash值计算结果，直接上传分片，同时把分片操作使用多4线程+异步的方式进行上传处理。

### upload-core中的通用函数

**EventEmitter**
统一前后端涉及到的基于各种事件的处理，使用发布订阅模式提供统一的EventEmitter类。比如
1. 前端可能出现的事件：上传进度改变事件，上传暂停/上传恢复事件
2. 后端可能出现的事件：分片写入完成事件，分片合并完成事件

```typescript
export class EventEmitter<T extends string> {
  private events: Map<T, Set<Function>>;
  constructor() {
    this.events = new Map();
  }

  on(event: T, listener: Function) {
    if(!this.events.has(event)){
      this.events.set(event, new Set());
    }
    this.events.get(event).add(listener);
  }

  off(event: T, listener: Function) {
    if(!this.events.has(event)) {
      return;
    }
    this.events.get(event).delete(listener);
  }

  once(event: T, listener: Function) {
    const onceListener = (...args: any[]) => {
      listener(...args);
      this.off(event, onceListener);
    }
    this.on(event, onceListener);
  }

  emit(event: T, ...args: any[]) {
    if(!this.events.has(event)) {
      return;
    }
    this.events.get(event).forEach(listener => listener(...args));
  }
}
```

**TaskQueue**
为支撑前后端的多任务并发执行，提供TaskQueue类，并发任务比如：
1. 前端可能得并发执行：并发请求
2. 后端可能得并发执行：并发的分片Hash校验

```typescript
export class Task {
  fn: Function; // 任务关联的执行函数
  payload?: any; // 任务关联的其他信息
  constructor(fn: Function, payload?: any) {
    this.fn = fn;
    this.payload = payload;
  }

  run() {
    return this.fn(this.payload);
  }
}

// 可并发执行的任务队列
export class TaskQueue extends EventEmitter<'start' | 'pause' | 'drain'> {
  // 待执行的任务
  private tasks: Set<Task> = new Set();
  // 当前正在执行的任务数
  private currentCount = 0;
  // 任务状态
  private status: 'paused' | 'running' = 'paused';
  // 最大并发数
  private concurrency: number = 4;

  constructor(concurrency: number = 4) {
    super();
    this.concurrency = concurrency;
  }

  // 添加任务
  add(...tasks: Task[]) {
    for (const t of tasks) {
      this.tasks.add(t);
    }
  }

  // 添加任务并启动执行
  addAndStart(...tasks: Task[]) {
    this.add(...tasks);
    this.start();
  }

  // 启动任务
  start() {
    if (this.status === 'running') {
      return; // 任务正在进行中，结束
    }
    if (this.tasks.size === 0) {
      // 当前已无任务，触发drain事件
      this.emit('drain');
      return;
    }
    // 设置任务状态为running
    this.status = 'running';
    this.emit('start'); // 触发start事件
    this.runNext(); // 开始执行下一个任务
  }

  // 取出第一个任务
  private takeHeadTask() {
    const task = this.tasks.values().next().value;
    if (task) {
      this.tasks.delete(task);
    }
    return task;
  }

  // 执行下一个任务
  private runNext() {
    if (this.status !== 'running') {
      return; // 如果整体的任务状态不是running，结束
    }
    if (this.currentCount >= this.concurrency) {
      // 并发数已满，结束
      return;
    }
    // 取出第一个任务
    const task = this.takeHeadTask();
    if (!task) {
      // 没有任务了
      this.status = 'paused'; // 暂停执行
      this.emit('drain'); // 触发drain事件
      return;
    }
    this.currentCount++; // 当前任务数+1
    // 执行任务
    Promise.resolve(task.run()).finally(() => {
      // 任务执行完成后，当前任务数-1，继续执行下一个任务
      this.currentCount--;
      this.runNext();
    });
  }

  // 暂停任务
  pause() {
    this.status = 'paused';
    this.emit('pause');
  }
}
```

### 前端要处理的问题

1. 如何分片
2. 控制请求

#### 如何对文件分片？

首先要实现分片对象的处理

```ts
// chunk.ts

export interface Chunk {
  blob: Blob; // 分片的二进制数据
  start: number; // 分片的起始位置
  end: number; // 分片的结束位置
  hash: string; // 分片的hash值
  index: number; // 分片在文件中的索引
}

// 创建一个不带hash的chunk
export function createChunk(
  file: File,
  index: number,
  chunkSize: number
): Chunk {
  const start = index * chunkSize;
  const end = Math.min((index + 1) * chunkSize, file.size);
  const blob = file.slice(start, end);
  return {
    blob,
    start,
    end,
    hash: '',
    index,
  };
}

// 计算chunk的hash值
export function calcChunkHash(chunk: Chunk): Promise<string> {
  return new Promise((resolve) => {
    const spark = new SparkMD5.ArrayBuffer();
    const fileReader = new FileReader();
    fileReader.onload = (e) => {
      spark.append(e.target?.result as ArrayBuffer);
      resolve(spark.end());
    };
    fileReader.readAsArrayBuffer(chunk.blob);
  });
}
```

接下来，要对整个文件进行分片，分片的方式有很多，比如：

- 普通分片
- 基于多线程的分片
- 基于主线程时间切片的分片（React Fiber）
- 其他分片模式

考虑到通用性，必须要向上层提供不同的分片模式，同时还要允许上层自定义分片模式，因此在设计上，使用基于抽象类的**模板模式**来完成处理。

```ts
// ChunkSplitor.ts

// 分片的相关事件
// chunks: 一部分分片产生了
// wholeHash: 整个文件的hash计算完成
// drain: 所有分片处理完成
export type ChunkSplitorEvents = 'chunks' | 'wholeHash' | 'drain';

export abstract class ChunkSplitor extends EventEmitter<ChunkSplitorEvents> {
  protected chunkSize: number; // 分片大小（单位字节）
  protected file: File; // 待分片的文件
  protected hash?: string; // 整个文件的hash
  protected chunks: Chunk[]; // 分片列表
  private handleChunkCount = 0; // 已计算hash的分片数量
  private spark = new SparkMD5(); // 计算hash的工具
  private hasSplited = false; // 是否已经分片
  constructor(file: File, chunkSize: number = 1024 * 1024 * 5) {
    super();
    this.file = file;
    this.chunkSize = chunkSize;
    // 获取分片数组
    const chunkCount = Math.ceil(this.file.size / this.chunkSize);
    this.chunks = new Array(chunkCount)
      .fill(0)
      .map((_, index) => createChunk(this.file, index, this.chunkSize));
  }

  split() {
    if (this.hasSplited) {
      return;
    }
    this.hasSplited = true;
    const emitter = new EventEmitter<'chunks'>();
    const chunksHanlder = (chunks: Chunk[]) => {
      this.emit('chunks', chunks);
      chunks.forEach((chunk) => {
        this.spark.append(chunk.hash);
      });
      this.handleChunkCount += chunks.length;
      if (this.handleChunkCount === this.chunks.length) {
        // 计算完成
        emitter.off('chunks', chunksHanlder);
        this.emit('wholeHash', this.spark.end());
        this.spark.destroy();
        this.emit('drain');
      }
    };
    emitter.on('chunks', chunksHanlder);
    this.calcHash(this.chunks, emitter);
  }

  // 计算每一个分片的hash
  abstract calcHash(chunks: Chunk[], emitter: EventEmitter<'chunks'>): void;

  // 分片完成后一些需要销毁的工作
  abstract dispose(): void;
}
```

基于此抽象类，即可实现多种形式的分片模式，每种模式只需要继承`ChunkSplitor`，实现计算分片的hash即可。

比如，基于多线程的分片类可以非常简单的实现：

```ts
// MutilThreadSplitor.ts

export class MultiThreadSplitor extends ChunkSplitor {
  private workers: Worker[] = new Array(navigator.hardwareConcurrency || 4)
    .fill(0)
    .map(
      () =>
        new Worker(new URL('./SplitWorker.ts', import.meta.url), {
          type: 'module',
        })
    );

  calcHash(chunks: Chunk[], emitter: EventEmitter<'chunks'>): void {
    const workerSize = Math.ceil(chunks.length / this.workers.length);
    for(let i = 0; i < this.workers.length; i++) {
      const worker = this.workers[i];
      const start = i * workerSize;
      const end = Math.min((i + 1) * workerSize, chunks.length);
      const workerChunks = chunks.slice(start, end);
      worker.postMessage(workerChunks);
      worker.onmessage = (e) => {
        emitter.emit('chunks', e.data);
      };
    }
  }
  dispose(): void {
    this.workers.forEach((worker) => worker.terminate());
  }
}

// SplitWorker.ts
onmessage = function (e) {
  const chunks = e.data as Chunk[];
  for (const chunk of chunks) {
    calcChunkHash(chunk).then((hash) => {
      chunk.hash = hash;
      postMessage([chunk]);
    });
  }
};
```

#### 如何控制请求？

对请求的控制涉及到多个方面的问题：

1. **如何充分利用带宽**
   分片上传中涉及到大量的请求发送，这些请求既不能一起发送造成网络阻塞，也不能依次发送浪费带宽资源，因此需要有请求并发控制的机制。
   **方案**： 利用基础库的TaskQueue实现并发控制

2. 如何与上层请求库解耦

   考虑到通用性，上层应用可能会使用各种请求库来发送请求，因此前端SDK不能绑定任何的请求库。
   **方案**： 这里使用**策略模式**对请求库解耦。

这个类比较复杂，下面贴出核心代码结构

`请求策略`

```ts
// 请求策略
export interface RequestStrategy {
  // 文件创建请求，返回token
  createFile(file: File): Promise<string>;
  // 分片上传请求
  uploadChunk(chunk: Chunk): Promise<void>;
  // 文件合并请求，返回文件url
  mergeFile(token: string): Promise<string>;
  // hash校验请求
  patchHash<T extends 'file' | 'chunk'>(
    token: string,
    hash: string,
    type: T
  ): Promise<
    T extends 'file'
      ? { hasFile: boolean }
      : { hasFile: boolean; rest: number[]; url: string }
  >;
}
```

`请求控制`

```ts
export class UploadController {
  private requestStrategy: RequestStrategy; // 请求策略，没有传递则使用默认策略
  private splitStrategy: ChunkSplitor; // 分片策略，没有传递则默认多线程分片
  private taskQueue: TaskQueue; // 任务队列
  // 其他属性略

  // 初始化
  async init() {
    // 获取文件token
    this.token = await this.requestStrategy.createFile(this.file);
    // 分片事件监听
    this.splitStrategy.on('chunks', this.handleChunks.bind(this));
    this.splitStrategy.on('wholeHash', this.handleWholeHash.bind(this));
  }

  // 分片事件处理
  private handleChunks(chunks: Chunk[]) {
    // 分片上传任务加入队列
    chunks.forEach((chunk) => {
      this.taskQueue.addAndStart(new Task(this.uploadChunk.bind(this), chunk));
    });
  }

  async uploadChunk(chunk: Chunk) {
    // hash校验
    const resp = await this.requestStrategy.patchHash(this.token, chunk.hash, 'chunk');
    if (resp.hasFile) {
      // 文件已存在
      return;
    }
    // 分片上传
    await this.requestStrategy.uploadChunk(chunk, this.uploadEmitter);
    
  }

  // 整体hash事件处理
  private async handleWholeHash(hash: string) {
    // hash校验
    const resp = await this.requestStrategy.patchHash(this.token, hash, 'file');
    if (resp.hasFile) {
      // 文件已存在
      this.emit('end', resp.url);
      return;
    }
    // 根据resp.rest重新编排后续任务
    // ...
  }
}
```